{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c499f4d-99e1-4057-8b1b-abb85458674b",
   "metadata": {
    "id": "7c499f4d-99e1-4057-8b1b-abb85458674b",
    "outputId": "dc59f186-3f83-4078-f803-58bbbda2638f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/sinzlab/neuralpredictors.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170eb67-dd42-4360-8a09-b2cd7e0d4edb",
   "metadata": {
    "id": "9170eb67-dd42-4360-8a09-b2cd7e0d4edb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e4b42-131b-402b-a2ae-9af0da990362",
   "metadata": {
    "id": "525e4b42-131b-402b-a2ae-9af0da990362"
   },
   "outputs": [],
   "source": [
    "!pip3 install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac0bb6-4691-4efa-8721-faa169d70cc8",
   "metadata": {
    "id": "d9ac0bb6-4691-4efa-8721-faa169d70cc8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944dd0ee-be73-405e-983d-838aefa8f015",
   "metadata": {
    "id": "944dd0ee-be73-405e-983d-838aefa8f015"
   },
   "outputs": [],
   "source": [
    "from utils import download_with_requests, set_background\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from digital_twin_library import SubsetSampler, corr, PoissonLoss\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neuralpredictors.data.datasets import FileTreeDataset\n",
    "\n",
    "from neuralpredictors.data.transforms import (\n",
    "    ToTensor,\n",
    "    NeuroNormalizer,\n",
    "    ScaleInputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cd949-38f8-403a-9379-8663057dd8df",
   "metadata": {
    "id": "a20cd949-38f8-403a-9379-8663057dd8df"
   },
   "source": [
    "# Data\n",
    "\n",
    "Let's download some data from the sensorium competition 2022. You can check out all datasets [here](\"https://gin.g-node.org/cajal/Sensorium2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c1cb4-77d7-4371-8005-601a076f4c66",
   "metadata": {
    "id": "539c1cb4-77d7-4371-8005-601a076f4c66"
   },
   "outputs": [],
   "source": [
    "!unzip -n -q /datasets/day01/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip -d sensorium_data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181971cb-7c47-4f59-bf73-a18746a9b1d2",
   "metadata": {
    "id": "181971cb-7c47-4f59-bf73-a18746a9b1d2"
   },
   "source": [
    "Let's look at the content of the data quickly. It contains images shown to a mouse, responses of cell in primary visual cortex (deconvolved Calcium activity), behavior of the animal (running and pupil dilation), and the location of the pupil center in an eye tracking video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e379a-d1e9-4e89-840c-8ddaad0fb610",
   "metadata": {
    "id": "ec4e379a-d1e9-4e89-840c-8ddaad0fb610"
   },
   "outputs": [],
   "source": [
    "ls sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e96a1-b3e2-46d5-a546-1b984d0d82ad",
   "metadata": {
    "id": "081e96a1-b3e2-46d5-a546-1b984d0d82ad"
   },
   "outputs": [],
   "source": [
    "ls sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6/data/images/100*.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2eb5b-9e94-4fc9-a675-96a06849cbe4",
   "metadata": {
    "id": "7dd2eb5b-9e94-4fc9-a675-96a06849cbe4"
   },
   "outputs": [],
   "source": [
    "img = np.load('sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6/data/images/0.npy')\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4d8b0-7c2d-4a29-9129-185119f0d311",
   "metadata": {
    "id": "4bb4d8b0-7c2d-4a29-9129-185119f0d311"
   },
   "outputs": [],
   "source": [
    "responses = np.load('sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6/data/responses/0.npy')\n",
    "responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d7349-38a5-4ade-931e-ee58becf559c",
   "metadata": {
    "id": "4b7d7349-38a5-4ade-931e-ee58becf559c"
   },
   "source": [
    "The data contains gray scale images of size `144 x 256` and the corresponding responses of `8372` neurons in mouse primary visual cortex. For now, we'll ignore the behavior and the pupil and only use images and neuronal responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d181-398f-4ddd-b265-b15c3c477dd4",
   "metadata": {
    "id": "0e97d181-398f-4ddd-b265-b15c3c477dd4"
   },
   "source": [
    "We can build a pytorch dataset for this data, using the the `FileTreeDataset` of `neuralpredictors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b9a73-de0a-4fec-a4e9-ba2d976b7a50",
   "metadata": {
    "id": "e52b9a73-de0a-4fec-a4e9-ba2d976b7a50"
   },
   "outputs": [],
   "source": [
    "from neuralpredictors.data.datasets import FileTreeDataset\n",
    "\n",
    "root_dir = 'sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6'\n",
    "dat = FileTreeDataset(root_dir, 'images', 'responses')\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043dad8-30a3-4137-aff7-609c370c714b",
   "metadata": {
    "id": "e043dad8-30a3-4137-aff7-609c370c714b"
   },
   "source": [
    "Together with a sampler, we can create a pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880e21a-b409-47fd-a28e-fb0556bd3e1a",
   "metadata": {
    "id": "5880e21a-b409-47fd-a28e-fb0556bd3e1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_sampler = SubsetSampler(dat.trial_info.tiers == 'train', shuffle=True)\n",
    "train_loader = DataLoader(dat, sampler=train_sampler, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef608172-332a-462d-92ba-76e2d6623a29",
   "metadata": {
    "id": "ef608172-332a-462d-92ba-76e2d6623a29"
   },
   "source": [
    "Now we can iterate through this data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508890d3-5079-41fd-bef9-2bdfeb2731c4",
   "metadata": {
    "id": "508890d3-5079-41fd-bef9-2bdfeb2731c4"
   },
   "outputs": [],
   "source": [
    "for images, responses in train_loader:\n",
    "    print(images.shape, responses.shape, type(images))\n",
    "    print(f\"Image mean+-std={images.mean()}+-{images.std()}\")\n",
    "    print(f\"Reponses mean+-std={responses.mean()}+-{responses.std()}\")\n",
    "    break # let's stop after the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004106f3-3437-4e51-9ba0-5ecc9b556f95",
   "metadata": {
    "id": "004106f3-3437-4e51-9ba0-5ecc9b556f95"
   },
   "source": [
    "For our purpose here, the images are still a bit big (training time), so we let's downscale them by a factor of 4. In addition, let's standardize the pixel values and scale the neuronal responses to have std=1. We can do that with the help of a few functions in `neuralpredictors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf1bb0-2c20-4703-9f31-f5b4db6e90ee",
   "metadata": {
    "id": "0adf1bb0-2c20-4703-9f31-f5b4db6e90ee"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root_dir = 'sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6'\n",
    "dat = FileTreeDataset(root_dir, 'images', 'responses')\n",
    "\n",
    "transforms = [NeuroNormalizer(dat), ScaleInputs(scale=0.25), ToTensor(torch.cuda.is_available())]\n",
    "dat.transforms.extend(transforms)\n",
    "\n",
    "\n",
    "train_sampler = SubsetSampler(dat.trial_info.tiers == 'train', shuffle=True)\n",
    "train_loader = DataLoader(dat, sampler=train_sampler, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26d569-82b6-4489-b042-6d7570611694",
   "metadata": {
    "id": "2c26d569-82b6-4489-b042-6d7570611694"
   },
   "outputs": [],
   "source": [
    "for images, responses in train_loader:\n",
    "    print(images.shape, responses.shape, type(images))\n",
    "    print(f\"Image mean+-std={images.mean()}+-{images.std()}\")\n",
    "    print(f\"Reponses mean+-std={responses.mean()}+-{responses.std()}\")\n",
    "    break # let's stop after the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e0f8b-b727-4def-a0d1-32bce098950c",
   "metadata": {
    "id": "f88e0f8b-b727-4def-a0d1-32bce098950c"
   },
   "source": [
    "# Train our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be56f23-c4f2-4a3e-a13a-43d9c1a3982c",
   "metadata": {
    "id": "9be56f23-c4f2-4a3e-a13a-43d9c1a3982c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root_dir = 'sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6'\n",
    "dat = FileTreeDataset(root_dir, 'images', 'responses')\n",
    "\n",
    "transforms = [ScaleInputs(scale=0.125), ToTensor(torch.cuda.is_available())]\n",
    "dat.transforms.extend(transforms)\n",
    "\n",
    "train_sampler = SubsetSampler(dat.trial_info.tiers == 'train', shuffle=True)\n",
    "test_sampler = SubsetSampler(dat.trial_info.tiers == 'test', shuffle=False)\n",
    "val_sampler = SubsetSampler(dat.trial_info.tiers == 'validation', shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(dat, sampler=train_sampler, batch_size=64)\n",
    "val_loader = DataLoader(dat, sampler=val_sampler, batch_size=64)\n",
    "test_loader = DataLoader(dat, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "print(f\"The training device is: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e53da-9e0c-4f68-963d-bb0187fe1cb5",
   "metadata": {
    "id": "283e53da-9e0c-4f68-963d-bb0187fe1cb5"
   },
   "source": [
    "<div class=\"task\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b47cfc-b6fd-4c30-9ae5-61101119127f",
   "metadata": {
    "id": "37b47cfc-b6fd-4c30-9ae5-61101119127f"
   },
   "source": [
    "## First model\n",
    "\n",
    "Now we are ready to build our first model. Please go through the tasks in order and see how/whether the performance of the model improves\n",
    "\n",
    "1. Below you find a simple linear model. Write code to train the model on the training data.\n",
    "    * What kind of loss could you use?\n",
    "    * Monitor the performance (correlation) on the validation all 5 epochs (epoch=full sweep through the training data).\n",
    "1. You'll find that the model is slow and does not train very well. Now try the following improvements and see how they increase the prediction performance.\n",
    "    * Decrease the image resolution to `18 x 32`.\n",
    "    * Add a `nn.BatchNorm1d` layer before the linear layer (make sure to put the model into `train` and `eval` mode respectively).\n",
    "    * Add `weight_decay=1e-4` to the optimizer.\n",
    "    * Add a rectifying nonlinearity `ReLU`, `Softplus` or `ELU + 1`.\n",
    "    * Change the loss to `digital_twin_library.PoissonLoss`.\n",
    "1. For the best model, produce plots that\n",
    "    * compare the performance (correlation) between validation and train for all neurons.\n",
    "    * plot linear filters (as grayscale images) of the best `n=12` neurons. What would you expect to see?\n",
    "1. Think about the following questions\n",
    "    * How many parameters does the model have?\n",
    "    * Is there any benefit from having many neurons?\n",
    "    * **Advanced**: The Poisson loss strictly a \"correct\" loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87582796-1f01-458c-a134-62330e1e6301",
   "metadata": {
    "id": "87582796-1f01-458c-a134-62330e1e6301"
   },
   "outputs": [],
   "source": [
    "class GLM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten the images\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b994a-7d9d-44a2-afc4-66015e3f4231",
   "metadata": {
    "id": "781b994a-7d9d-44a2-afc4-66015e3f4231"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042b28e-7a74-4e1f-808a-ec5647325df3",
   "metadata": {
    "id": "9042b28e-7a74-4e1f-808a-ec5647325df3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036541d0-6b3c-4594-a9c7-38f5ba9d41c3",
   "metadata": {
    "id": "036541d0-6b3c-4594-a9c7-38f5ba9d41c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acd65a-bf46-4d17-aa07-f7fc84f41986",
   "metadata": {
    "id": "29acd65a-bf46-4d17-aa07-f7fc84f41986"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3edb57e-00dc-4ae3-925f-4b4e8e36e86e",
   "metadata": {
    "id": "b3edb57e-00dc-4ae3-925f-4b4e8e36e86e"
   },
   "source": [
    "# Improving the model\n",
    "\n",
    "Let's improve the model. First, let's use resolution `36 x 64` from now on. Also, let's standardize the images to `mean+-std=0+-1` and the neuronal responses to `std=1` (we keep them positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07636d83-7ae0-4704-9a19-b2b4b6a32d33",
   "metadata": {
    "id": "07636d83-7ae0-4704-9a19-b2b4b6a32d33"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "root_dir = 'sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6'\n",
    "dat = FileTreeDataset(root_dir, 'images', 'responses')\n",
    "\n",
    "transforms = [NeuroNormalizer(dat), ScaleInputs(scale=0.25), ToTensor(torch.cuda.is_available())]\n",
    "dat.transforms.extend(transforms)\n",
    "\n",
    "train_sampler = SubsetSampler(dat.trial_info.tiers == 'train', shuffle=True)\n",
    "test_sampler = SubsetSampler(dat.trial_info.tiers == 'test', shuffle=False)\n",
    "val_sampler = SubsetSampler(dat.trial_info.tiers == 'validation', shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(dat, sampler=train_sampler, batch_size=64)\n",
    "val_loader = DataLoader(dat, sampler=val_sampler, batch_size=64)\n",
    "test_loader = DataLoader(dat, sampler=test_sampler, batch_size=64)\n",
    "\n",
    "print(f\"The training device is: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04226fdf-423d-4f6b-baac-441e5410f6ad",
   "metadata": {
    "id": "04226fdf-423d-4f6b-baac-441e5410f6ad"
   },
   "source": [
    "Let's now try to make our model better. You can try the following options\n",
    "\n",
    "1. Make the model convolutional:\n",
    "    * Instead of a linear layer, use a convolutional network with layers `(Conv2D, Batchnorm2D, Nonlinearity)`.\n",
    "    * Use a final linear layer + rectifying nonlinearity to map the output of the network to the neurons.\n",
    "    * A good start is 3 convolutional layers + final linear layer.\n",
    "    * How many parameters does your model have? Is there a benefit of having many neurons now?\n",
    "2. Reduce parameters\n",
    "   * Replace the convolution by depthwise separable convolutions\n",
    "   * Factorize the readout as in [Klindt et al. 2017](https://arxiv.org/abs/1711.02653).\n",
    "   * **Advanced**: Implement a Gaussian Readout as in [Lurz et al. 2021](https://openreview.net/pdf?id=Tp7kI90Htd).\n",
    "3. Improve the training routine\n",
    "   * Use early stopping: Monitor the validation correlation. If it has not gone up for `patience` epochs, set the model to the best model so far and stop training.\n",
    "   * Use learning rate schedules: Instead of stopping training, reduce the learning rate once or twice (e.g. with [ReduceLROnPlateau](https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html) ).\n",
    "\n",
    "**Challenge**:\n",
    "Let's make this a competition. Try to get the best model you can with the above (or other) tricks. We'll maintain a leader board at the front. Report your best validation correlation to us and we mark it down. Obviously, you're not allowed to train on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1a673-216c-45c6-a697-1afbb63c9e2e",
   "metadata": {
    "id": "4ca1a673-216c-45c6-a697-1afbb63c9e2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee6201-e4a7-40db-9a2e-404e0ab2e747",
   "metadata": {
    "id": "afee6201-e4a7-40db-9a2e-404e0ab2e747"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeab198-a556-4dd7-8ce1-5ed20dfae6b3",
   "metadata": {
    "id": "feeab198-a556-4dd7-8ce1-5ed20dfae6b3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87087ab1-0a88-46e0-8009-179cb17efabc",
   "metadata": {
    "id": "87087ab1-0a88-46e0-8009-179cb17efabc"
   },
   "source": [
    "# Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4314e6-0549-434e-bcdc-914b643ff143",
   "metadata": {
    "id": "fd4314e6-0549-434e-bcdc-914b643ff143"
   },
   "source": [
    "Now that we have a well trained model, we can start analyzing it. However, unlike before, we cannot simply plot linear filters. However, we can run classical analyses (and more) on the model. In the following block we'll look at receptive fields.\n",
    "\n",
    "1. Run spike triggered averages on the model. I.e. present the model with Gaussian white noise (what previous modelling choice was important for that?) and record the responses. Then, for each if the best 12 neurons, compute the weighted mean of the noise frames using the predicted response of the neuron as weights. Plot the resulting images. What can you observe?\n",
    "\n",
    "2. What happens if you do 1. with natural images. How can you explain the difference?\n",
    "\n",
    "3. In stead of using STA, send the zero image through the model and compute the gradient with respect to the image. This can be done via\n",
    "\n",
    "    ```python\n",
    "    rfs = []\n",
    "    for i in best[:12]:\n",
    "        x = torch.zeros(1, 1, 36, 64).to(device)\n",
    "        x.requires_grad = True\n",
    "        r = model_m(x)\n",
    "        r[0, i].backward()\n",
    "        rfs.append(x.grad.cpu().numpy().squeeze())\n",
    "    ```\n",
    "    \n",
    "    Plot the resulting images, too. What can you observe? Can you explain why you get this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c26f9-d548-4ae6-8e85-217f96320a45",
   "metadata": {
    "id": "e98c26f9-d548-4ae6-8e85-217f96320a45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250a090-eb44-498d-b92e-e97a3731e2c6",
   "metadata": {
    "id": "b250a090-eb44-498d-b92e-e97a3731e2c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8e469d-2796-427a-8c64-7327224818f1",
   "metadata": {
    "id": "fc8e469d-2796-427a-8c64-7327224818f1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629dc4b-5a12-4dd7-9053-ed308f2f9beb",
   "metadata": {
    "id": "b629dc4b-5a12-4dd7-9053-ed308f2f9beb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00286f13-8bce-480b-a31d-15db691a7d8a",
   "metadata": {
    "id": "00286f13-8bce-480b-a31d-15db691a7d8a"
   },
   "source": [
    "# Optional: How good is good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bf31e-f5aa-478d-ad54-54b1c93d07a4",
   "metadata": {
    "id": "d37bf31e-f5aa-478d-ad54-54b1c93d07a4"
   },
   "source": [
    "The best models so far, probably reached about `0.3` in correlation. Since correlation goes up until `1` this might not seem like a good result. However, neuronal responses are noisy. So even if we had the best predictor, we would not reach `1`. Thus, the question arises what's the best we could do.\n",
    "\n",
    "For many loss functions, the best predictor is the conditional mean, i.e. the average response to the same image over many repetitions. We can estimate this response from repeated presentations of the same stimulus. The dataset actually contains these kind of repetitions. However, for that we need a new sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b399c-2577-4beb-b403-92e64b689778",
   "metadata": {
    "id": "cd5b399c-2577-4beb-b403-92e64b689778"
   },
   "outputs": [],
   "source": [
    " # this sampler groups all responses to the same image in one batch\n",
    "from neuralpredictors.data.samplers import RepeatsBatchSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66607c2f-ebd5-4a57-b20a-06d140a81a56",
   "metadata": {
    "id": "66607c2f-ebd5-4a57-b20a-06d140a81a56"
   },
   "outputs": [],
   "source": [
    "root_dir = 'sensorium_data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6'\n",
    "dat = FileTreeDataset(root_dir, 'images', 'responses')\n",
    "\n",
    "transforms = [NeuroNormalizer(dat), ScaleInputs(scale=0.25), ToTensor(torch.cuda.is_available())]\n",
    "dat.transforms.extend(transforms)\n",
    "\n",
    "test_sampler = RepeatsBatchSampler(dat.trial_info.frame_image_id, np.where(dat.trial_info.tiers == 'test')[0])\n",
    "\n",
    "test_loader = DataLoader(dat, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d080c756-8918-4aec-bb01-5dc70049333c",
   "metadata": {
    "id": "d080c756-8918-4aec-bb01-5dc70049333c"
   },
   "source": [
    "Test that you actually get the same image in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2c1fb-03c3-4965-a450-3bce2ed76886",
   "metadata": {
    "id": "4ff2c1fb-03c3-4965-a450-3bce2ed76886"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02da3a3-cd8b-48d2-8c6b-b9f007b9effc",
   "metadata": {
    "id": "b02da3a3-cd8b-48d2-8c6b-b9f007b9effc"
   },
   "source": [
    "Now use this dataset to compute an \"oracle\" predictor. Consider the response $y_{ij}$ of a neuron to the $i$th image shown the $j$th time. To compute the oracle predictor for this trial, we average all responses of that neuron to this image over all **but** the $j$th trial\n",
    "\n",
    "$$\\hat y_{ij} = \\frac{1}{n-1} \\sum_{k\\not=j} y_{ik}$$\n",
    "\n",
    "where $n$ is the number of repeats. Then use this predictor and correlate it with all $y_{ij}$ as if the oracle were model predictions. Compare that to the predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3ded4-33c1-46df-a8e7-71a51188e135",
   "metadata": {
    "id": "39c3ded4-33c1-46df-a8e7-71a51188e135"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411dc60-21c5-4444-b223-39fe6c086805",
   "metadata": {
    "id": "f411dc60-21c5-4444-b223-39fe6c086805"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efe40d-10e6-4a53-ae53-d55f9a80c465",
   "metadata": {
    "id": "a6efe40d-10e6-4a53-ae53-d55f9a80c465"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
